{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport skimage.io as skio\nimport torch.optim as optim\nimport skimage as sk\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:01:53.590404Z","iopub.execute_input":"2023-11-03T03:01:53.591203Z","iopub.status.idle":"2023-11-03T03:01:53.596976Z","shell.execute_reply.started":"2023-11-03T03:01:53.591171Z","shell.execute_reply":"2023-11-03T03:01:53.596074Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:01:56.488906Z","iopub.execute_input":"2023-11-03T03:01:56.489774Z","iopub.status.idle":"2023-11-03T03:01:56.521967Z","shell.execute_reply.started":"2023-11-03T03:01:56.489734Z","shell.execute_reply":"2023-11-03T03:01:56.520830Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = np.load(f\"/kaggle/input/280-proj5/lego_200x200.npz\")\nimages_train = data[\"images_train\"] / 255.0\nc2ws_train = data[\"c2ws_train\"]\nimages_val = data[\"images_val\"] / 255.0\nc2ws_val = data[\"c2ws_val\"]\nc2ws_test = data[\"c2ws_test\"]\nfocal = data[\"focal\"]","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:10.154614Z","iopub.execute_input":"2023-11-03T03:02:10.154972Z","iopub.status.idle":"2023-11-03T03:02:10.326062Z","shell.execute_reply.started":"2023-11-03T03:02:10.154946Z","shell.execute_reply":"2023-11-03T03:02:10.325028Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":73,"outputs":[{"name":"stdout","output_type":"stream","text":"(100, 200, 200, 3)\n"}]},{"cell_type":"code","source":"height = 200\nwidth = 200\nn_samples = 32","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:12.885536Z","iopub.execute_input":"2023-11-03T03:02:12.885909Z","iopub.status.idle":"2023-11-03T03:02:12.890527Z","shell.execute_reply.started":"2023-11-03T03:02:12.885881Z","shell.execute_reply":"2023-11-03T03:02:12.889461Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"K = np.array([[focal,0,width/2],[0,focal,height/2],[0,0,1]])","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:14.745408Z","iopub.execute_input":"2023-11-03T03:02:14.745767Z","iopub.status.idle":"2023-11-03T03:02:14.751248Z","shell.execute_reply.started":"2023-11-03T03:02:14.745739Z","shell.execute_reply":"2023-11-03T03:02:14.749920Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# c2w = c2ws_train[0]","metadata":{},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# c2w","metadata":{},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def transform(c2w, x_c):\n    #camera to world\n    num_rows = len(x_c)\n    ones_column = np.ones((num_rows, 1))\n    x_c_with_one = np.concatenate((x_c, ones_column), axis=1)\n    x = (c2w @ x_c_with_one.T).T\n    return x[:,:-1]","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:18.027003Z","iopub.execute_input":"2023-11-03T03:02:18.027378Z","iopub.status.idle":"2023-11-03T03:02:18.032742Z","shell.execute_reply.started":"2023-11-03T03:02:18.027347Z","shell.execute_reply":"2023-11-03T03:02:18.031794Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"aaa = np.array([[0,0,0]])\nprint(transform(c2w, aaa))","metadata":{},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"[[-0.05379832  3.84547043  1.20808232]]\n"}]},{"cell_type":"code","source":"w2c = np.linalg.inv(c2w)","metadata":{},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(-np.linalg.inv(w2c[:3,:3]) @ w2c[:3,3])","metadata":{},"execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"[-0.05379832  3.84547043  1.20808232]\n"}]},{"cell_type":"code","source":"def pixel_to_camera(K, uv,s):\n    num_rows = len(uv)\n    ones_column = np.ones((num_rows, 1))\n    uv_with_one = np.concatenate((uv, ones_column), axis=1)\n    result = (np.linalg.inv(K) @ uv_with_one.T).T\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:24.326051Z","iopub.execute_input":"2023-11-03T03:02:24.326912Z","iopub.status.idle":"2023-11-03T03:02:24.331766Z","shell.execute_reply.started":"2023-11-03T03:02:24.326879Z","shell.execute_reply":"2023-11-03T03:02:24.330814Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"aaa = np.array([[1,2,3],[10,11,12],[20,21,22],[21,22,23]])\nb = np.array([[0.9,2,3]])\nc = aaa - b\nnorms = np.linalg.norm(c, axis=1, keepdims=True)\nprint(norms)\nprint(c/norms)","metadata":{},"execution_count":63,"outputs":[{"name":"stdout","output_type":"stream","text":"[[ 0.1       ]\n\n [15.64640534]\n\n [32.96680148]\n\n [34.69884724]]\n\n[[1.         0.         0.        ]\n\n [0.58160324 0.57521199 0.57521199]\n\n [0.57937073 0.57633738 0.57633738]\n\n [0.57926996 0.57638802 0.57638802]]\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pixel_to_ray(K, c2w, uv):\n    zeros = np.array([[0,0,0]])\n    origin = transform(c2w, zeros)\n    depth_1_points = pixel_to_camera(K, uv, 1)\n    world_depth_1_points = transform(c2w, depth_1_points)\n    world_depth_1_points_direction = world_depth_1_points - origin\n    norms = np.linalg.norm(world_depth_1_points_direction, axis=1, keepdims=True)\n    directions = world_depth_1_points_direction/ norms\n\n    return origin, directions\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:28.256201Z","iopub.execute_input":"2023-11-03T03:02:28.257112Z","iopub.status.idle":"2023-11-03T03:02:28.262615Z","shell.execute_reply.started":"2023-11-03T03:02:28.257077Z","shell.execute_reply":"2023-11-03T03:02:28.261717Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RaysData(Dataset):\n    def __init__(self, img_train, K, c2ws_train):\n        self.img = img_train\n        self.c2ws = c2ws_train\n        self.K = K\n        self.height = 200\n        self.width = 200\n        self.length = len(self.img) * self.height * self.width\n\n    def __len__(self):\n        return len(self.img * self.height * self.width)\n    \n    def __getitem__(self, idx):\n        pass\n        # x = idx // self.width \n        # y = idx % self.width \n        # rgb = [self.image[x,y,0],\n        #        self.image[x,y,1],\n        #        self.image[x,y,2]]\n        # sample = {'input':torch.tensor([x/self.height,y/ self.width]),\n        #           \"label\":torch.tensor(rgb)}\n        # return sample\n\n    def sample_rays(self, num_samples):\n        rays_o = []\n        rays_d = []\n        pixels = []\n        random_numbers = [random.randint(0,self.length -1) for _ in range(num_samples)]\n        for random_number in random_numbers:\n            img_index = random_number // (self.width*self.height)\n            residual = random_number % (self.width*self.height)\n            temp_height = residual // self.height\n            temp_width = residual % self.width\n            c2w = self.c2ws[img_index]\n            uv = np.array([[temp_height, temp_width]])\n            ray_o, ray_d = pixel_to_ray(self.K, c2w, uv)\n            rays_o.append(ray_o[0])\n            rays_d.append(ray_d[0])\n            pixels.append(self.img[img_index,temp_height,temp_width,:])\n        return rays_o, rays_d,pixels\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:30.821104Z","iopub.execute_input":"2023-11-03T03:02:30.821861Z","iopub.status.idle":"2023-11-03T03:02:30.833421Z","shell.execute_reply.started":"2023-11-03T03:02:30.821823Z","shell.execute_reply":"2023-11-03T03:02:30.832476Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset = RaysData(images_train, K, c2ws_train)\n# rays_o, rays_d, pixels = dataset.sample_rays(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:35.711992Z","iopub.execute_input":"2023-11-03T03:02:35.712385Z","iopub.status.idle":"2023-11-03T03:02:35.717117Z","shell.execute_reply.started":"2023-11-03T03:02:35.712354Z","shell.execute_reply":"2023-11-03T03:02:35.716020Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# def sample_along_rays(rays_o, rays_d, perturb = True):\n#     far = 6 \n#     near = 2\n#     n_samples = 32\n#     points = []\n#     for ray_o, ray_d in zip(rays_o, rays_d):\n#         for t in np.linspace(near, far, n_samples):\n#             ran = random.uniform(0, (far - near)/n_samples)\n#             p_t = t + ran\n#             points.append(ray_o + ray_d * p_t)\n#     return np.array(points)","metadata":{},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def sample_along_rays(rays_o, rays_d, n_samples = 32, perturb = True):\n    far = 6 \n    near = 2\n    points = []\n    for ray_o, ray_d in zip(rays_o, rays_d):\n        for t in np.linspace(near, far, n_samples):\n            ran = random.uniform(0, (far - near)/n_samples)\n            p_t = t + ran\n            points.append(ray_o + ray_d * p_t)\n    return np.array(points)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:37.688904Z","iopub.execute_input":"2023-11-03T03:02:37.689778Z","iopub.status.idle":"2023-11-03T03:02:37.695632Z","shell.execute_reply.started":"2023-11-03T03:02:37.689744Z","shell.execute_reply":"2023-11-03T03:02:37.694539Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# points = sample_along_rays(rays_o, rays_d)\n# print(len(points))","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n\nimport viser, time  # pip install viser\nimport numpy as np\n\n# --- You Need to Implement These ------\ndataset = RaysData(images_train, K, c2ws_train)\nrays_o, rays_d, pixels = dataset.sample_rays(5)\npoints = sample_along_rays(rays_o, rays_d, perturb=True)\nH, W = images_train.shape[1:3]","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"server = viser.ViserServer(share=True)\nfor i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n    server.add_camera_frustum(\n        f\"/cameras/{i}\",\n        fov=2 * np.arctan2(H / 2, K[0, 0]),\n        aspect=W / H,\n        scale=0.15,\n        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n        position=c2w[:3, 3],\n        image=image\n    )\nfor i, (o, d) in enumerate(zip(rays_o, rays_d)):\n    server.add_spline_catmull_rom(\n        f\"/rays/{i}\", positions=np.stack((o, o + d * 6.0)),\n    )\nserver.add_point_cloud(\n    f\"/samples\",\n    colors=np.zeros_like(points).reshape(-1, 3),\n    points=points.reshape(-1, 3),\n    point_size=0.02,\n)\ntime.sleep(1000)","metadata":{},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL requested! <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL requested! \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours\u001b[1m)\u001b[0m\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────── <span style=\"font-weight: bold\">viser</span> ──────────────────────────────╮\n","│             ╷                                                    │\n","│   HTTP      │ http://0.0.0.0:8080                                │\n","│   Websocket │ ws://0.0.0.0:8080                                  │\n","│   Share URL │ https://transparent-augmented.share.viser.studio   │\n","│             ╵                                                    │\n","╰──────────────────────────────────────────────────────────────────╯\n","</pre>\n"],"text/plain":["╭───────────────────────────── \u001b[1mviser\u001b[0m ──────────────────────────────╮\n","│             ╷                                                    │\n","│   HTTP      │ http://0.0.0.0:8080                                │\n","│   Websocket │ ws://0.0.0.0:8080                                  │\n","│   Share URL │ https://transparent-augmented.share.viser.studio   │\n","│             ╵                                                    │\n","╰──────────────────────────────────────────────────────────────────╯\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">411</span> persistent messages\n","</pre>\n"],"text/plain":["\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m411\u001b[0m persistent messages\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"]},"metadata":{}},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m     server\u001b[38;5;241m.\u001b[39madd_spline_catmull_rom(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/rays/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, positions\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mstack((o, o \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6.0\u001b[39m)),\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m server\u001b[38;5;241m.\u001b[39madd_point_cloud(\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/samples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     colors\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(points)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     19\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     20\u001b[0m     point_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":"def volrend(sigmas, rgbs, step_size):\n    sigmas = sigmas.to(device)\n    rgbs = rgbs.to(device)\n    size_to_prepend = (sigmas.size(0), 1, 1)\n\n    zeros_to_prepend = torch.zeros(size_to_prepend, dtype=sigmas.dtype).to(device)\n    \n    tensor_with_zeros = torch.cat((zeros_to_prepend, sigmas), dim=1).to(device)\n\n    \n    \n    cum_sigmas = torch.cumsum(tensor_with_zeros,dim=1)[:,:-1].to(device)\n    T = torch.exp(-cum_sigmas*step_size).to(device)\n    interval_sigmas = 1 - torch.exp(-sigmas*step_size).to(device)\n    weights = T * interval_sigmas\n    colors = rgbs * weights\n    cum_colors = torch.sum(colors, dim=1).to(device)\n\n    return cum_colors","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:02:42.729099Z","iopub.execute_input":"2023-11-03T03:02:42.730078Z","iopub.status.idle":"2023-11-03T03:02:42.737754Z","shell.execute_reply.started":"2023-11-03T03:02:42.730039Z","shell.execute_reply":"2023-11-03T03:02:42.736675Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\nsigmas = torch.rand((10, 64, 1)) * 1000\nrgbs = torch.rand((10, 64, 3))\nstep_size = (6.0 - 2.0) / 64\nrendered_colors = volrend(sigmas, rgbs, step_size)\ncorrect = torch.tensor([\n  [0.6020, 0.0316, 0.9366],\n  [0.0620, 0.2249, 0.1381],\n  [0.7785, 0.4253, 0.7124],\n  [0.8748, 0.5055, 0.7411],\n  [0.2240, 0.5240, 0.4298],\n  [0.0531, 0.7500, 0.0501],\n  [0.0458, 0.9415, 0.4620],\n  [0.6692, 0.3450, 0.0991],\n  [0.7392, 0.6365, 0.3080],\n  [0.2425, 0.9346, 0.9305]]\n).to(device)\nassert torch.allclose(rendered_colors, correct, rtol=1e-4, atol=1e-4)","metadata":{},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Nerf_model(nn.Module):\n    def __init__(self,high_fre_level, high_fre_level_angle, hidden_dim):\n        super(Nerf_model, self).__init__()\n        self.high_fre_level = high_fre_level\n        self.high_fre_level_angle = high_fre_level_angle\n        self.pe_dim = 3+high_fre_level*6\n        self.pe_dim_angle = 3 + 6 * high_fre_level_angle\n        self.input_layer = nn.Linear(3+high_fre_level*6, hidden_dim)\n        # self.input_layer = nn.Linear(2, hidden_dim)\n        hidden_layer_list = []\n        for i in range(3):\n            hidden_layer_list.append(nn.Linear(hidden_dim, hidden_dim))\n            hidden_layer_list.append(nn.ReLU())\n        self.hidden_layer_1 = nn.Sequential(*hidden_layer_list)\n\n        self.concat_hidden_layer = nn.Linear(hidden_dim + self.pe_dim,hidden_dim)\n        \n        hidden_layer_list = []\n        for i in range(2):\n            hidden_layer_list.append(nn.Linear(hidden_dim, hidden_dim))\n            hidden_layer_list.append(nn.ReLU())\n        self.hidden_layer_2 = nn.Sequential(*hidden_layer_list)\n\n        self.hidden_layer_3 = nn.Linear(hidden_dim, hidden_dim)\n        self.hidden_layer_4 = nn.Linear(hidden_dim, hidden_dim)\n        self.hidden_layer_5 = nn.Linear(hidden_dim, hidden_dim)\n        self.hidden_layer_concat_angle = nn.Linear(hidden_dim + self.pe_dim_angle, hidden_dim//2)\n\n        self.out = nn.Linear(hidden_dim//2, 3)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n        self.angle_layer = nn.Linear(hidden_dim, 1)\n\n#     def positional_encoding(self, data, high_fre_level):\n#         d = data.shape[1]\n#         length = len(data)\n#         data = data.to(device)\n#         pe = torch.zeros(length, high_fre_level*2*d).to(device)\n#         div_term = torch.exp2(torch.arange(0, high_fre_level))*3.14159\n#         div_term = div_term.to(device)\n#         for i in range(len(data)):\n#             for j in range(d):\n#                 pe[i, 2*j*high_fre_level:high_fre_level*(j+1)*2:2] = torch.sin(data[i,j] * div_term)\n#                 pe[i, 1 + 2*j*high_fre_level:high_fre_level*(j+1)*2+1:2] = torch.cos(data[i,j] * div_term)\n#         return pe\n    \n    \n    def positional_encoding(self, data, high_fre_level):\n        d = data.shape[1]\n        length = len(data)\n        data = data.to(device)\n        pe = torch.zeros(length, high_fre_level*2*d).to(device)\n        div_term = torch.exp2(torch.arange(0, high_fre_level))*3.14159\n        div_term = div_term.to(device)\n\n        for i in range(len(div_term)):\n            for j in range(d):\n                pe[:,2*i+j] =  torch.sin(data[:,j] * div_term[i])\n                pe[:,2*i+j+d] =  torch.cos(data[:,j] * div_term[i])\n        return pe\n        \n    def forward_phase_1(self, origin_x):\n        # print(origin_x.dtype)\n        x = self.input_layer(origin_x)\n        x = self.relu(x)\n        x = self.hidden_layer_1(x)\n        x = torch.cat((x,origin_x), dim = 1)\n        x = self.concat_hidden_layer(x)\n        x = self.relu(x)\n        x = self.hidden_layer_2(x)\n        x = self.hidden_layer_3(x)\n        return x\n\n    # def foward_dentisy(self, origin_x):\n    #     x = forward_phase_1(origin_x)\n    #     return self.angle_layer(x)\n        \n    def forward(self, pos, angle):\n        \n        pos_pe = self.positional_encoding(pos, self.high_fre_level)\n        \n        origin_x = torch.cat((pos,pos_pe),dim=1).float()\n        x = self.forward_phase_1(origin_x)\n        x = self.hidden_layer_4(x)\n        sigmas = self.angle_layer(x)\n        sigmas = self.relu(sigmas)\n        \n        x = self.hidden_layer_5(x)\n        angle_pe = self.positional_encoding(angle, self.high_fre_level_angle)\n        angle_input = torch.cat((angle,angle_pe),dim=1)\n        concated_x = torch.cat((x,angle_input), dim = 1).float()\n        x = self.hidden_layer_concat_angle(concated_x)\n        x = self.relu(x)\n        x = self.out(x)\n        x = self.sigmoid(x)\n        return x, sigmas\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:46:39.644689Z","iopub.execute_input":"2023-11-03T03:46:39.645049Z","iopub.status.idle":"2023-11-03T03:46:39.664492Z","shell.execute_reply.started":"2023-11-03T03:46:39.645022Z","shell.execute_reply":"2023-11-03T03:46:39.663443Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PSNRWithMSELoss(nn.Module):\n    def __init__(self):\n        super(PSNRWithMSELoss, self).__init__()\n        \n    def forward(self, predicted, target):\n        # mse_loss = nn.MSELoss()(predicted, target)\n        # mse_loss = nn.MSELoss()(predicted, target)\n        # psnr = 10 * torch.log10(1 / mse_loss)\n        mse_loss = torch.mean((predicted - target) ** 2)\n        psnr = 10 * torch.log10(1 / mse_loss)\n        return psnr","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:45:39.542546Z","iopub.execute_input":"2023-11-03T03:45:39.542920Z","iopub.status.idle":"2023-11-03T03:45:39.548908Z","shell.execute_reply.started":"2023-11-03T03:45:39.542892Z","shell.execute_reply":"2023-11-03T03:45:39.547971Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(n_samples)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:54:15.756214Z","iopub.execute_input":"2023-11-03T03:54:15.757117Z","iopub.status.idle":"2023-11-03T03:54:15.761635Z","shell.execute_reply.started":"2023-11-03T03:54:15.757083Z","shell.execute_reply":"2023-11-03T03:54:15.760700Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"32\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Nerf_model(10,4,256).to(device)\nstep_size = (6-2)/n_samples","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:46:46.331696Z","iopub.execute_input":"2023-11-03T03:46:46.332068Z","iopub.status.idle":"2023-11-03T03:46:46.345796Z","shell.execute_reply.started":"2023-11-03T03:46:46.332039Z","shell.execute_reply":"2023-11-03T03:46:46.344813Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:17:08.205097Z","iopub.execute_input":"2023-11-03T03:17:08.205472Z","iopub.status.idle":"2023-11-03T03:17:08.210491Z","shell.execute_reply.started":"2023-11-03T03:17:08.205442Z","shell.execute_reply":"2023-11-03T03:17:08.209385Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.01)\n# criterion = PSNRWithMSELoss()\ncriterion = torch.nn.MSELoss()\nnumber_iteration  = 100\nmodel.train()\nfor i in range(number_iteration):\n    dataset = RaysData(images_train, K, c2ws_train)\n\n    \n    rays_o, rays_d, pixels = dataset.sample_rays(10000)\n\n    \n    points = sample_along_rays(rays_o, rays_d)\n    \n\n    \n    points = np.array(points)\n    rays_d = np.array(rays_d)\n    points = torch.tensor(points).to(device)\n    rays_d = torch.tensor(rays_d).to(device)\n    \n    rays_d = torch.unsqueeze(rays_d,1)\n    rays_d = rays_d.repeat(1,n_samples,1)\n    rays_d = rays_d.view(-1,3)\n    \n    rgbs, sigmas = model(points, rays_d)\n\n    \n    rgbs = rgbs.to(device)\n    sigmas = sigmas.to(device)\n    # sigams = model.foward_dentisy()\n    sigmas = sigmas.view(-1, n_samples, 1)\n    rgbs = rgbs.view(-1, n_samples, 3)\n    \n\n\n    \n    rendered_colors = volrend(sigmas, rgbs, step_size)\n    \n\n    \n    pixels = torch.tensor(pixels).float().to(device)\n    loss = criterion(rendered_colors, pixels)\n    \n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # if (i_batch) % 10000 == 0:\n    print(f'iteration [{i}], Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2023-11-03T03:54:47.033283Z","iopub.execute_input":"2023-11-03T03:54:47.034164Z","iopub.status.idle":"2023-11-03T04:00:45.898344Z","shell.execute_reply.started":"2023-11-03T03:54:47.034131Z","shell.execute_reply":"2023-11-03T04:00:45.897217Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"iteration [0], Loss: 0.08622807264328003\niteration [1], Loss: 0.08339633792638779\niteration [2], Loss: 0.08430500328540802\niteration [3], Loss: 0.08514223247766495\niteration [4], Loss: 0.08523578941822052\niteration [5], Loss: 0.08177034556865692\niteration [6], Loss: 0.08780424296855927\niteration [7], Loss: 0.08434592932462692\niteration [8], Loss: 0.0893477350473404\niteration [9], Loss: 0.08443676680326462\niteration [10], Loss: 0.0871710330247879\niteration [11], Loss: 0.08691491186618805\niteration [12], Loss: 0.08867481350898743\niteration [13], Loss: 0.08474596589803696\niteration [14], Loss: 0.08479420840740204\niteration [15], Loss: 0.08820820599794388\niteration [16], Loss: 0.08621136844158173\niteration [17], Loss: 0.08469957858324051\niteration [18], Loss: 0.08221520483493805\niteration [19], Loss: 0.08529423922300339\niteration [20], Loss: 0.08514349907636642\niteration [21], Loss: 0.09012327343225479\niteration [22], Loss: 0.08508054167032242\niteration [23], Loss: 0.08483001589775085\niteration [24], Loss: 0.08681193739175797\niteration [25], Loss: 0.08952977508306503\niteration [26], Loss: 0.08542399108409882\niteration [27], Loss: 0.08552488684654236\niteration [28], Loss: 0.08465558290481567\niteration [29], Loss: 0.08570410311222076\niteration [30], Loss: 0.08855977654457092\niteration [31], Loss: 0.08465765416622162\niteration [32], Loss: 0.08708878606557846\niteration [33], Loss: 0.08686260133981705\niteration [34], Loss: 0.08581685274839401\niteration [35], Loss: 0.08846496045589447\niteration [36], Loss: 0.08764523267745972\niteration [37], Loss: 0.08231861889362335\niteration [38], Loss: 0.0862291008234024\niteration [39], Loss: 0.08734606206417084\niteration [40], Loss: 0.08465626835823059\niteration [41], Loss: 0.08111513406038284\niteration [42], Loss: 0.08446177840232849\niteration [43], Loss: 0.0847826674580574\niteration [44], Loss: 0.08607222139835358\niteration [45], Loss: 0.08449197560548782\niteration [46], Loss: 0.08659518510103226\niteration [47], Loss: 0.08541984111070633\niteration [48], Loss: 0.08499539643526077\niteration [49], Loss: 0.08532889932394028\niteration [50], Loss: 0.08668535202741623\niteration [51], Loss: 0.08400710672140121\niteration [52], Loss: 0.08518204838037491\niteration [53], Loss: 0.08709274232387543\niteration [54], Loss: 0.08618418872356415\niteration [55], Loss: 0.0858776867389679\niteration [56], Loss: 0.08413863927125931\niteration [57], Loss: 0.08704951405525208\niteration [58], Loss: 0.085125632584095\niteration [59], Loss: 0.08245589584112167\niteration [60], Loss: 0.08579519391059875\niteration [61], Loss: 0.08436094969511032\niteration [62], Loss: 0.08593608438968658\niteration [63], Loss: 0.0835864394903183\niteration [64], Loss: 0.08306899666786194\niteration [65], Loss: 0.0839957445859909\niteration [66], Loss: 0.08800527453422546\niteration [67], Loss: 0.08456739783287048\niteration [68], Loss: 0.08476296812295914\niteration [69], Loss: 0.08569378405809402\niteration [70], Loss: 0.0857139602303505\niteration [71], Loss: 0.08497253060340881\niteration [72], Loss: 0.08799842745065689\niteration [73], Loss: 0.0864260271191597\niteration [74], Loss: 0.08553152531385422\niteration [75], Loss: 0.08819461613893509\niteration [76], Loss: 0.08385206013917923\niteration [77], Loss: 0.08595339953899384\niteration [78], Loss: 0.08385618031024933\niteration [79], Loss: 0.08274821192026138\niteration [80], Loss: 0.08584950119256973\niteration [81], Loss: 0.08410327881574631\niteration [82], Loss: 0.08680367469787598\niteration [83], Loss: 0.08427435159683228\niteration [84], Loss: 0.08179238438606262\niteration [85], Loss: 0.0857134535908699\niteration [86], Loss: 0.08348282426595688\niteration [87], Loss: 0.08246845006942749\niteration [88], Loss: 0.08846612274646759\niteration [89], Loss: 0.08538147807121277\niteration [90], Loss: 0.08611958473920822\niteration [91], Loss: 0.08683513104915619\niteration [92], Loss: 0.0866965726017952\niteration [93], Loss: 0.08652308583259583\niteration [94], Loss: 0.08480237424373627\niteration [95], Loss: 0.08372274786233902\niteration [96], Loss: 0.08526883274316788\niteration [97], Loss: 0.0859563797712326\niteration [98], Loss: 0.08700953423976898\niteration [99], Loss: 0.08471310138702393\n","output_type":"stream"}]},{"cell_type":"code","source":"# uv = []\n# for i in range(200):\n#     uv.append([0,i])\n# uv = np.array(uv)\n# ray_o, ray_d = pixel_to_ray(K, c2w_eval, uv)","metadata":{},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\neval_height = 200\neval_width = 200\nc2w_eval = c2ws_train[0]\nresults = torch.zeros((eval_height, eval_width,3)).to(device)\nfor i in range(eval_height):\n    uv = []\n    for j in range(eval_width):\n        uv.append([i,j])\n    ray_o, ray_d = pixel_to_ray(K, c2w_eval, uv)\n    rays_o = np.repeat(ray_o, eval_height, axis=0)\n    rays_d = list(ray_d)\n    points = sample_along_rays(rays_o, rays_d)\n    points = torch.tensor(points).to(device)\n    rays_d = torch.tensor(rays_d).to(device)\n    rays_d = torch.unsqueeze(rays_d,1)\n    rays_d = rays_d.repeat(1,n_samples,1)\n    rays_d = rays_d.view(-1,3)\n    \n    rgbs, sigmas = model(points, rays_d)\n    rgbs = rgbs.to(device)\n    sigmas = sigmas.to(device)\n    # sigams = model.foward_dentisy()\n    sigmas = sigmas.view(-1, n_samples, 1)\n    rgbs = rgbs.view(-1, n_samples, 3)\n    rendered_colors = volrend(sigmas, rgbs, step_size)\n    # print(rendered_colors.shape)\n    results[i,:,:] = rendered_colors","metadata":{"execution":{"iopub.status.busy":"2023-11-03T04:02:13.886808Z","iopub.execute_input":"2023-11-03T04:02:13.887152Z","iopub.status.idle":"2023-11-03T04:02:32.868458Z","shell.execute_reply.started":"2023-11-03T04:02:13.887128Z","shell.execute_reply":"2023-11-03T04:02:32.867017Z"},"trusted":true},"execution_count":45,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m rays_d \u001b[38;5;241m=\u001b[39m rays_d\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,n_samples,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m rays_d \u001b[38;5;241m=\u001b[39m rays_d\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m rgbs, sigmas \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrays_d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m rgbs \u001b[38;5;241m=\u001b[39m rgbs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m sigmas \u001b[38;5;241m=\u001b[39m sigmas\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[35], line 83\u001b[0m, in \u001b[0;36mNerf_model.forward\u001b[0;34m(self, pos, angle)\u001b[0m\n\u001b[1;32m     80\u001b[0m pos_pe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(pos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh_fre_level)\n\u001b[1;32m     82\u001b[0m origin_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((pos,pos_pe),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_phase_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_4(x)\n\u001b[1;32m     85\u001b[0m sigmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle_layer(x)\n","Cell \u001b[0;32mIn[35], line 69\u001b[0m, in \u001b[0;36mNerf_model.forward_phase_1\u001b[0;34m(self, origin_x)\u001b[0m\n\u001b[1;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x,origin_x), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat_hidden_layer(x)\n\u001b[0;32m---> 69\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_2(x)\n\u001b[1;32m     71\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_3(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 14.58 GiB already allocated; 35.75 MiB free; 15.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 14.58 GiB already allocated; 35.75 MiB free; 15.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"results = results.detach().cpu().numpy()\nskio.imshow(results)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T04:02:06.657372Z","iopub.execute_input":"2023-11-03T04:02:06.658388Z","iopub.status.idle":"2023-11-03T04:02:06.974984Z","shell.execute_reply.started":"2023-11-03T04:02:06.658351Z","shell.execute_reply":"2023-11-03T04:02:06.973971Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7fc25527cb80>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}