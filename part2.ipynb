{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c446ff2-9c90-4db2-9dab-3ccb9848386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.io as skio\n",
    "import torch.optim as optim\n",
    "import skimage as sk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1203c5-dd8f-497a-bfb5-f2f70ab9406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a984cd0-189d-4285-b3f6-bb6ceb86a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f\"lego_200x200.npz\")\n",
    "images_train = data[\"images_train\"] / 255.0\n",
    "c2ws_train = data[\"c2ws_train\"]\n",
    "images_val = data[\"images_val\"] / 255.0\n",
    "c2ws_val = data[\"c2ws_val\"]\n",
    "c2ws_test = data[\"c2ws_test\"]\n",
    "focal = data[\"focal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1af29b4b-5ed2-4079-ae85-e48cd58ba5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 200, 200, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d09713a-f81e-4b4a-bbf9-2ebbb6224f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 200\n",
    "width = 200\n",
    "n_samples = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c066449d-5ee8-4f80-9288-69dd904a52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[focal,0,width/2],[0,focal,height/2],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6756e1cb-d746-4ac7-b8af-8df9afd1e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2w = c2ws_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f13f49-7864-439c-b988-78a168fbe204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704781ce-f547-4535-bcd4-2107d6c7d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(c2w, x_c):\n",
    "    #camera to world\n",
    "    num_rows = len(x_c)\n",
    "    ones_column = np.ones((num_rows, 1))\n",
    "    x_c_with_one = np.concatenate((x_c, ones_column), axis=1)\n",
    "    x = (c2w @ x_c_with_one.T).T\n",
    "    return x[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e3503d-9a43-4f25-b9f3-31ae9a749683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05379832  3.84547043  1.20808232]]\n"
     ]
    }
   ],
   "source": [
    "aaa = np.array([[0,0,0]])\n",
    "print(transform(c2w, aaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a078e626-ee0c-469c-83c8-6bf47de26101",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = np.linalg.inv(c2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6392c32-88ff-463e-80dd-374f766d9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05379832  3.84547043  1.20808232]\n"
     ]
    }
   ],
   "source": [
    "print(-np.linalg.inv(w2c[:3,:3]) @ w2c[:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c967571e-60d8-4f6c-907e-f14cae891ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_camera(K, uv,s):\n",
    "    num_rows = len(uv)\n",
    "    ones_column = np.ones((num_rows, 1))\n",
    "    uv_with_one = np.concatenate((uv, ones_column), axis=1)\n",
    "    result = (np.linalg.inv(K) @ uv_with_one.T).T\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0258127d-c836-48cd-b60f-ca73d01d81f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1       ]\n",
      " [15.64640534]\n",
      " [32.96680148]\n",
      " [34.69884724]]\n",
      "[[1.         0.         0.        ]\n",
      " [0.58160324 0.57521199 0.57521199]\n",
      " [0.57937073 0.57633738 0.57633738]\n",
      " [0.57926996 0.57638802 0.57638802]]\n"
     ]
    }
   ],
   "source": [
    "aaa = np.array([[1,2,3],[10,11,12],[20,21,22],[21,22,23]])\n",
    "b = np.array([[0.9,2,3]])\n",
    "c = aaa - b\n",
    "norms = np.linalg.norm(c, axis=1, keepdims=True)\n",
    "print(norms)\n",
    "print(c/norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c50e2f-acf4-4e04-a9a2-b9e4d60170b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2132818-51f7-48d2-a045-74ebd6661bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_ray(K, c2w, uv):\n",
    "    zeros = np.array([[0,0,0]])\n",
    "    origin = transform(c2w, zeros)\n",
    "    depth_1_points = pixel_to_camera(K, uv, 1)\n",
    "    world_depth_1_points = transform(c2w, depth_1_points)\n",
    "    world_depth_1_points_direction = world_depth_1_points - origin\n",
    "    norms = np.linalg.norm(world_depth_1_points_direction, axis=1, keepdims=True)\n",
    "    directions = world_depth_1_points_direction/ norms\n",
    "\n",
    "    return origin, directions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee2f75-fe71-4d5f-9e37-80f5e4524e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd398744-4b0a-4273-b008-1c911fd4b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaysData(Dataset):\n",
    "    def __init__(self, img_train, K, c2ws_train):\n",
    "        self.img = img_train\n",
    "        self.c2ws = c2ws_train\n",
    "        self.K = K\n",
    "        self.height = 200\n",
    "        self.width = 200\n",
    "        self.length = len(self.img) * self.height * self.width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img * self.height * self.width)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "        # x = idx // self.width \n",
    "        # y = idx % self.width \n",
    "        # rgb = [self.image[x,y,0],\n",
    "        #        self.image[x,y,1],\n",
    "        #        self.image[x,y,2]]\n",
    "        # sample = {'input':torch.tensor([x/self.height,y/ self.width]),\n",
    "        #           \"label\":torch.tensor(rgb)}\n",
    "        # return sample\n",
    "\n",
    "    def sample_rays(self, num_samples):\n",
    "        rays_o = []\n",
    "        rays_d = []\n",
    "        pixels = []\n",
    "        random_numbers = [random.randint(0,self.length -1) for _ in range(num_samples)]\n",
    "        for random_number in random_numbers:\n",
    "            img_index = random_number // (self.width*self.height)\n",
    "            residual = random_number % (self.width*self.height)\n",
    "            temp_height = residual // self.height\n",
    "            temp_width = residual % self.width\n",
    "            c2w = self.c2ws[img_index]\n",
    "            uv = np.array([[temp_height, temp_width]])\n",
    "            ray_o, ray_d = pixel_to_ray(self.K, c2w, uv)\n",
    "            rays_o.append(ray_o[0])\n",
    "            rays_d.append(ray_d[0])\n",
    "            pixels.append(self.img[img_index,temp_height,temp_width,:])\n",
    "        return rays_o, rays_d,pixels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76051041-06ab-424a-855f-8f5016a5096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "# rays_o, rays_d, pixels = dataset.sample_rays(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1da66976-9b61-48e9-8126-2acdcd424fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_along_rays(rays_o, rays_d, perturb = True):\n",
    "#     far = 6 \n",
    "#     near = 2\n",
    "#     n_samples = 32\n",
    "#     points = []\n",
    "#     for ray_o, ray_d in zip(rays_o, rays_d):\n",
    "#         for t in np.linspace(near, far, n_samples):\n",
    "#             ran = random.uniform(0, (far - near)/n_samples)\n",
    "#             p_t = t + ran\n",
    "#             points.append(ray_o + ray_d * p_t)\n",
    "#     return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3136877-9387-4b22-bc61-49c1512b477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_along_rays(rays_o, rays_d, n_samples = 32, perturb = True):\n",
    "    far = 6 \n",
    "    near = 2\n",
    "    points = []\n",
    "    for ray_o, ray_d in zip(rays_o, rays_d):\n",
    "        for t in np.linspace(near, far, n_samples):\n",
    "            ran = random.uniform(0, (far - near)/n_samples)\n",
    "            p_t = t + ran\n",
    "            points.append(ray_o + ray_d * p_t)\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92b103b-0fa5-4c78-b3c7-3f0ae98726d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = sample_along_rays(rays_o, rays_d)\n",
    "# print(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af6b290-7144-4d3c-9b96-a111cde81f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import viser, time  # pip install viser\n",
    "import numpy as np\n",
    "\n",
    "# --- You Need to Implement These ------\n",
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "rays_o, rays_d, pixels = dataset.sample_rays(5)\n",
    "points = sample_along_rays(rays_o, rays_d, perturb=True)\n",
    "H, W = images_train.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d706fc-dd2c-4e67-b0a8-18e03951cd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL requested! <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL requested! \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────── <span style=\"font-weight: bold\">viser</span> ──────────────────────────────╮\n",
       "│             ╷                                                    │\n",
       "│   HTTP      │ http://0.0.0.0:8080                                │\n",
       "│   Websocket │ ws://0.0.0.0:8080                                  │\n",
       "│   Share URL │ https://transparent-augmented.share.viser.studio   │\n",
       "│             ╵                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭───────────────────────────── \u001b[1mviser\u001b[0m ──────────────────────────────╮\n",
       "│             ╷                                                    │\n",
       "│   HTTP      │ http://0.0.0.0:8080                                │\n",
       "│   Websocket │ ws://0.0.0.0:8080                                  │\n",
       "│   Share URL │ https://transparent-augmented.share.viser.studio   │\n",
       "│             ╵                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">411</span> persistent messages\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m411\u001b[0m persistent messages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m     server\u001b[38;5;241m.\u001b[39madd_spline_catmull_rom(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/rays/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, positions\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mstack((o, o \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6.0\u001b[39m)),\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m server\u001b[38;5;241m.\u001b[39madd_point_cloud(\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/samples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     colors\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(points)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     19\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     20\u001b[0m     point_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "server = viser.ViserServer(share=True)\n",
    "for i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n",
    "    server.add_camera_frustum(\n",
    "        f\"/cameras/{i}\",\n",
    "        fov=2 * np.arctan2(H / 2, K[0, 0]),\n",
    "        aspect=W / H,\n",
    "        scale=0.15,\n",
    "        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n",
    "        position=c2w[:3, 3],\n",
    "        image=image\n",
    "    )\n",
    "for i, (o, d) in enumerate(zip(rays_o, rays_d)):\n",
    "    server.add_spline_catmull_rom(\n",
    "        f\"/rays/{i}\", positions=np.stack((o, o + d * 6.0)),\n",
    "    )\n",
    "server.add_point_cloud(\n",
    "    f\"/samples\",\n",
    "    colors=np.zeros_like(points).reshape(-1, 3),\n",
    "    points=points.reshape(-1, 3),\n",
    "    point_size=0.02,\n",
    ")\n",
    "time.sleep(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ccd6c7-4214-4a59-9ce6-4419332622e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volrend(sigmas, rgbs, step_size):\n",
    "    sigmas = sigmas.to(device)\n",
    "    rgbs = rgbs.to(device)\n",
    "    size_to_prepend = (sigmas.size(0), 1, 1)\n",
    "\n",
    "    zeros_to_prepend = torch.zeros(size_to_prepend, dtype=sigmas.dtype).to(device)\n",
    "    \n",
    "    tensor_with_zeros = torch.cat((zeros_to_prepend, sigmas), dim=1).to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "    cum_sigmas = torch.cumsum(tensor_with_zeros,dim=1)[:,:-1].to(device)\n",
    "    T = torch.exp(-cum_sigmas*step_size).to(device)\n",
    "    interval_sigmas = 1 - torch.exp(-sigmas*step_size).to(device)\n",
    "    weights = T * interval_sigmas\n",
    "    colors = rgbs * weights\n",
    "    cum_colors = torch.sum(colors, dim=1).to(device)\n",
    "\n",
    "    return cum_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f29ba80-c2a2-408e-8e54-0730a2aa14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "sigmas = torch.rand((10, 64, 1)) * 1000\n",
    "rgbs = torch.rand((10, 64, 3))\n",
    "step_size = (6.0 - 2.0) / 64\n",
    "rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "correct = torch.tensor([\n",
    "  [0.6020, 0.0316, 0.9366],\n",
    "  [0.0620, 0.2249, 0.1381],\n",
    "  [0.7785, 0.4253, 0.7124],\n",
    "  [0.8748, 0.5055, 0.7411],\n",
    "  [0.2240, 0.5240, 0.4298],\n",
    "  [0.0531, 0.7500, 0.0501],\n",
    "  [0.0458, 0.9415, 0.4620],\n",
    "  [0.6692, 0.3450, 0.0991],\n",
    "  [0.7392, 0.6365, 0.3080],\n",
    "  [0.2425, 0.9346, 0.9305]]\n",
    ").to(device)\n",
    "assert torch.allclose(rendered_colors, correct, rtol=1e-4, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4aa32-9c1c-4300-af6b-acba881a3cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a90feb-7b69-4161-bc23-a4c3e19e477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nerf_model(nn.Module):\n",
    "    def __init__(self,high_fre_level, high_fre_level_angle, hidden_dim):\n",
    "        super(Nerf_model, self).__init__()\n",
    "        self.high_fre_level = high_fre_level\n",
    "        self.high_fre_level_angle = high_fre_level_angle\n",
    "        self.pe_dim = 3+high_fre_level*6\n",
    "        self.pe_dim_angle = 3 + 6 * high_fre_level_angle\n",
    "        self.input_layer = nn.Linear(3+high_fre_level*6, hidden_dim)\n",
    "        # self.input_layer = nn.Linear(2, hidden_dim)\n",
    "        hidden_layer_list = []\n",
    "        for i in range(3):\n",
    "            hidden_layer_list.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            hidden_layer_list.append(nn.ReLU())\n",
    "        self.hidden_layer_1 = nn.Sequential(*hidden_layer_list)\n",
    "\n",
    "        self.concat_hidden_layer = nn.Linear(hidden_dim + self.pe_dim,hidden_dim)\n",
    "        \n",
    "        hidden_layer_list = []\n",
    "        for i in range(2):\n",
    "            hidden_layer_list.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            hidden_layer_list.append(nn.ReLU())\n",
    "        self.hidden_layer_2 = nn.Sequential(*hidden_layer_list)\n",
    "\n",
    "        self.hidden_layer_3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hidden_layer_4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hidden_layer_5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hidden_layer_concat_angle = nn.Linear(hidden_dim + self.pe_dim_angle, hidden_dim//2)\n",
    "\n",
    "        self.out = nn.Linear(hidden_dim//2, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.angle_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def positional_encoding(self, data, high_fre_level):\n",
    "        d = data.shape[1]\n",
    "        length = len(data)\n",
    "        data = data.to(device)\n",
    "        pe = torch.zeros(length, high_fre_level*2*d).to(device)\n",
    "        div_term = torch.exp2(torch.arange(0, high_fre_level))*3.14159\n",
    "        div_term = div_term.to(device)\n",
    "        for i in range(len(data)):\n",
    "            for j in range(d):\n",
    "                pe[i, 2*j*high_fre_level:high_fre_level*(j+1)*2:2] = torch.sin(data[i,j] * div_term)\n",
    "                pe[i, 1 + 2*j*high_fre_level:high_fre_level*(j+1)*2+1:2] = torch.cos(data[i,j] * div_term)\n",
    "        return pe\n",
    "        \n",
    "    def forward_phase_1(self, origin_x):\n",
    "        # print(origin_x.dtype)\n",
    "        x = self.input_layer(origin_x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden_layer_1(x)\n",
    "        x = torch.cat((x,origin_x), dim = 1)\n",
    "        x = self.concat_hidden_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = self.hidden_layer_3(x)\n",
    "        return x\n",
    "\n",
    "    # def foward_dentisy(self, origin_x):\n",
    "    #     x = forward_phase_1(origin_x)\n",
    "    #     return self.angle_layer(x)\n",
    "        \n",
    "    def forward(self, pos, angle):\n",
    "        pos_pe = self.positional_encoding(pos, self.high_fre_level)\n",
    "        origin_x = torch.cat((pos,pos_pe),dim=1).float()\n",
    "        x = self.forward_phase_1(origin_x)\n",
    "        x = self.hidden_layer_4(x)\n",
    "        sigmas = self.angle_layer(x)\n",
    "        sigmas = self.relu(sigmas)\n",
    "        \n",
    "        x = self.hidden_layer_5(x)\n",
    "        angle_pe = self.positional_encoding(angle, self.high_fre_level_angle)\n",
    "        angle_input = torch.cat((angle,angle_pe),dim=1)\n",
    "        concated_x = torch.cat((x,angle_input), dim = 1).float()\n",
    "        x = self.hidden_layer_concat_angle(concated_x)\n",
    "        x = self.relu(x)\n",
    "        x = self.out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x, sigmas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5f6ef-2917-470b-b601-337472574fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "47b3dd32-8085-4210-b1e7-bd02dc0024b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [0], Loss: 0.10159755498170853\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [1], Loss: 0.17140106856822968\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [2], Loss: 0.09804832935333252\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [3], Loss: 0.14086276292800903\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [4], Loss: 0.06375943124294281\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [5], Loss: 0.06186775863170624\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [6], Loss: 0.09290654957294464\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [7], Loss: 0.090561643242836\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [8], Loss: 0.07159743458032608\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [9], Loss: 0.06141278147697449\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [10], Loss: 0.03760664537549019\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [11], Loss: 0.03999125212430954\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [12], Loss: 0.030706316232681274\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [13], Loss: 0.056444425135850906\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [14], Loss: 0.02926657907664776\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [15], Loss: 0.02326056733727455\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [16], Loss: 0.08851778507232666\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [17], Loss: 0.03773362189531326\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [18], Loss: 0.056248001754283905\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [19], Loss: 0.0900767520070076\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [20], Loss: 0.1344342678785324\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [21], Loss: 0.031844109296798706\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [22], Loss: 0.06419640779495239\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [23], Loss: 0.03779676929116249\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [24], Loss: 0.026243828237056732\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [25], Loss: 0.06882544606924057\n",
      "4\n",
      "torch.Size([320, 3])\n",
      "torch.Size([320, 27])\n",
      "torch.Size([320, 283])\n",
      "iteration [26], Loss: 0.06008895859122276\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m rays_d \u001b[38;5;241m=\u001b[39m rays_d\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,n_samples,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m rays_d \u001b[38;5;241m=\u001b[39m rays_d\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m rgbs, sigmas \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrays_d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# sigams = model.foward_dentisy()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m sigmas \u001b[38;5;241m=\u001b[39m sigmas\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,n_samples,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[136], line 64\u001b[0m, in \u001b[0;36mNerf_model.forward\u001b[0;34m(self, pos, angle)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pos, angle):\n\u001b[0;32m---> 64\u001b[0m     pos_pe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositional_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhigh_fre_level\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     origin_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((pos,pos_pe),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_phase_1(origin_x)\n",
      "Cell \u001b[0;32mIn[136], line 44\u001b[0m, in \u001b[0;36mNerf_model.positional_encoding\u001b[0;34m(self, data, high_fre_level)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d):\n\u001b[1;32m     43\u001b[0m         pe[i, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mj\u001b[38;5;241m*\u001b[39mhigh_fre_level:high_fre_level\u001b[38;5;241m*\u001b[39m(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(data[i,j] \u001b[38;5;241m*\u001b[39m div_term)\n\u001b[0;32m---> 44\u001b[0m         pe[i, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mj\u001b[38;5;241m*\u001b[39mhigh_fre_level:high_fre_level\u001b[38;5;241m*\u001b[39m(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiv_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pe\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "# criterion = PSNRWithMSELoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# number_iteration  = 1000\n",
    "# for i in range(number_iteration):\n",
    "#     dataset = RaysData(images_train, K, c2ws_train)\n",
    "#     rays_o, rays_d, pixels = dataset.sample_rays(10)\n",
    "#     points = sample_along_rays(rays_o, rays_d)\n",
    "#     points = torch.tensor(points).to(device)\n",
    "#     rays_d = torch.tensor(rays_d).to(device)\n",
    "    \n",
    "#     rays_d = torch.unsqueeze(rays_d,1)\n",
    "#     rays_d = rays_d.repeat(1,n_samples,1)\n",
    "#     rays_d = rays_d.view(-1,3)\n",
    "    \n",
    "#     rgbs, sigmas = model(points, rays_d)\n",
    "#     # sigams = model.foward_dentisy()\n",
    "#     sigmas = sigmas.view(-1,n_samples,1)\n",
    "#     rgbs = rgbs.view(-1,n_samples,3)\n",
    "#     rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "#     pixels = torch.tensor(pixels).float().to(device)\n",
    "#     loss = criterion(rendered_colors, pixels)\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     # if (i_batch) % 10000 == 0:\n",
    "#     print(f'iteration [{i}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ae3e0-8563-4b9e-87db-25f944691dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "656a2c97-3199-4c7e-8f30-b084d5e33f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "torch.Size([2, 5, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# ttt = torch.tensor(([1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15],[16,17,18]))\n",
    "# tttt = ttt.view(-1,3,3)\n",
    "# print(tttt.shape)\n",
    "# print(tttt)\n",
    "\n",
    "aaaa = torch.tensor(([[1,2,3],[4,5,6]]))\n",
    "aaaaa = torch.unsqueeze(aaaa,1)\n",
    "print(aaaaa.shape)\n",
    "aaaaa = aaaaa.repeat(1,5,1)\n",
    "print(aaaaa.shape)\n",
    "aaaaaa = aaaaa.view(-1,3)\n",
    "print(aaaaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49d958ce-d119-469f-b796-28e97dc262a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSNRWithMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PSNRWithMSELoss, self).__init__()\n",
    "        \n",
    "    def forward(self, predicted, target):\n",
    "        # mse_loss = nn.MSELoss()(predicted, target)\n",
    "        # mse_loss = nn.MSELoss()(predicted, target)\n",
    "        # psnr = 10 * torch.log10(1 / mse_loss)\n",
    "        mse_loss = torch.mean((predicted - target) ** 2)\n",
    "        psnr = 10 * torch.log10(1 / mse_loss)\n",
    "        return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82bae047-6365-44af-880e-2c92abb4d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Nerf_model(10,4,256).to(device)\n",
    "step_size = (6-2)/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4b2f8e0-4eb9-4041-8baf-30a622247342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 19:46:30.392780: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-02 19:46:30.515437: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-02 19:46:31.250190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_4247/2814496965.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  rays_d = torch.tensor(rays_d).to(device)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m rays_d \u001b[38;5;241m=\u001b[39m rays_d\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,n_samples,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m rays_d \u001b[38;5;241m=\u001b[39m rays_d\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m rgbs, sigmas \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrays_d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m rgbs \u001b[38;5;241m=\u001b[39m rgbs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m sigmas \u001b[38;5;241m=\u001b[39m sigmas\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 72\u001b[0m, in \u001b[0;36mNerf_model.forward\u001b[0;34m(self, pos, angle)\u001b[0m\n\u001b[1;32m     69\u001b[0m sigmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(sigmas)\n\u001b[1;32m     71\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_5(x)\n\u001b[0;32m---> 72\u001b[0m angle_pe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositional_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhigh_fre_level_angle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m angle_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((angle,angle_pe),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m concated_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x,angle_input), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "Cell \u001b[0;32mIn[19], line 43\u001b[0m, in \u001b[0;36mNerf_model.positional_encoding\u001b[0;34m(self, data, high_fre_level)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d):\n\u001b[0;32m---> 43\u001b[0m         pe[i, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mj\u001b[38;5;241m*\u001b[39mhigh_fre_level:high_fre_level\u001b[38;5;241m*\u001b[39m(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiv_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m         pe[i, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mj\u001b[38;5;241m*\u001b[39mhigh_fre_level:high_fre_level\u001b[38;5;241m*\u001b[39m(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(data[i,j] \u001b[38;5;241m*\u001b[39m div_term)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pe\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = PSNRWithMSELoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "number_iteration  = 10\n",
    "model.train()\n",
    "for i in range(number_iteration):\n",
    "    dataset = RaysData(images_train, K, c2ws_train)\n",
    "    rays_o, rays_d, pixels = dataset.sample_rays(10000)\n",
    "    points = sample_along_rays(rays_o, rays_d)\n",
    "    points = torch.tensor(points).to(device)\n",
    "    rays_d = torch.tensor(rays_d).to(device)\n",
    "    \n",
    "    rays_d = torch.unsqueeze(rays_d,1)\n",
    "    rays_d = rays_d.repeat(1,n_samples,1)\n",
    "    rays_d = rays_d.view(-1,3)\n",
    "    \n",
    "    rgbs, sigmas = model(points, rays_d)\n",
    "    rgbs = rgbs.to(device)\n",
    "    sigmas = sigmas.to(device)\n",
    "    # sigams = model.foward_dentisy()\n",
    "    sigmas = sigmas.view(-1, n_samples, 1)\n",
    "    rgbs = rgbs.view(-1, n_samples, 3)\n",
    "    rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "    pixels = torch.tensor(pixels).float().to(device)\n",
    "    loss = criterion(rendered_colors, pixels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # if (i_batch) % 10000 == 0:\n",
    "    print(f'iteration [{i}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6febdcfa-efcd-4d01-8eed-62c622762cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv = []\n",
    "# for i in range(200):\n",
    "#     uv.append([0,i])\n",
    "# uv = np.array(uv)\n",
    "# ray_o, ray_d = pixel_to_ray(K, c2w_eval, uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8c7d6-fd17-4756-8e83-93388296de65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767774a-536e-482a-bc89-125bab7dd5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b348c-4fad-49ab-b03d-9f7b93343332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0574c18-50a4-4855-8fb6-dde0c64ab799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "480bed32-8326-40c1-ba3a-23ad1545a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "eval_height = 50\n",
    "eval_width = 50\n",
    "c2w_eval = c2ws_train[0]\n",
    "results = torch.zeros((eval_height, eval_width,3)).to(device)\n",
    "for i in range(eval_height):\n",
    "    uv = []\n",
    "    for j in range(eval_width):\n",
    "        uv.append([i,j])\n",
    "    ray_o, ray_d = pixel_to_ray(K, c2w_eval, uv)\n",
    "    rays_o = np.repeat(ray_o, eval_height, axis=0)\n",
    "    rays_d = list(ray_d)\n",
    "    points = sample_along_rays(rays_o, rays_d)\n",
    "    points = torch.tensor(points).to(device)\n",
    "    rays_d = torch.tensor(rays_d).to(device)\n",
    "    rays_d = torch.unsqueeze(rays_d,1)\n",
    "    rays_d = rays_d.repeat(1,n_samples,1)\n",
    "    rays_d = rays_d.view(-1,3)\n",
    "    \n",
    "    rgbs, sigmas = model(points, rays_d)\n",
    "    rgbs = rgbs.to(device)\n",
    "    sigmas = sigmas.to(device)\n",
    "    # sigams = model.foward_dentisy()\n",
    "    sigmas = sigmas.view(-1, n_samples, 1)\n",
    "    rgbs = rgbs.view(-1, n_samples, 3)\n",
    "    rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "    # print(rendered_colors.shape)\n",
    "    results[i,:,:] = rendered_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5bc4a0ba-ad2e-413b-9a42-c46b3f1dee7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yihua/anaconda3/lib/python3.10/site-packages/skimage/io/_plugins/matplotlib_plugin.py:150: UserWarning: Low image data range; displaying image with stretched contrast.\n",
      "  lo, hi, cmap = _get_display_range(image)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb81fe98640>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = results.detach().cpu().numpy()\n",
    "skio.imshow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08ae5f-1b79-4c7f-ac6f-9bbc5398b916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
