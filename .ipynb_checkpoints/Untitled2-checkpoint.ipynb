{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463ff663-9da0-4cb9-95af-cf3a049fbed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.io as skio\n",
    "import torch.optim as optim\n",
    "import skimage as sk\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432b2f05-e0fe-40bd-981f-72afba481286",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c322fc-acb6-4ec7-9401-11f958e2fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f\"lego_200x200.npz\")\n",
    "images_train = data[\"images_train\"] / 255.0\n",
    "c2ws_train = data[\"c2ws_train\"]\n",
    "images_val = data[\"images_val\"] / 255.0\n",
    "c2ws_val = data[\"c2ws_val\"]\n",
    "c2ws_test = data[\"c2ws_test\"]\n",
    "focal = data[\"focal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196e0b47-20bc-4428-a1ff-20ec4762184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 200\n",
    "width = 200\n",
    "n_samples = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020f3597-6e7b-4e8b-8425-b7240be35d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[focal,0,width/2],[0,focal,height/2],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47fa5710-c01a-41f8-ac9a-acfd740a4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(c2w, x_c):\n",
    "    #camera to world\n",
    "    num_rows = len(x_c)\n",
    "    ones_column = np.ones((num_rows, 1))\n",
    "    x_c_with_one = np.concatenate((x_c, ones_column), axis=1)\n",
    "    x = (c2w @ x_c_with_one.T).T\n",
    "    return x[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45caee41-8510-4019-a164-ae52812f3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_camera(K, uv,s):\n",
    "    num_rows = len(uv)\n",
    "    ones_column = np.ones((num_rows, 1))\n",
    "    uv_with_one = np.concatenate((uv, ones_column), axis=1)\n",
    "    result = (np.linalg.inv(K) @ uv_with_one.T).T\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe30cd8-8614-48cf-be40-7bd0da5aea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_ray(K, c2w, uv):\n",
    "    zeros = np.array([[0,0,0]])\n",
    "    origin = transform(c2w, zeros)\n",
    "    depth_1_points = pixel_to_camera(K, uv, 1)\n",
    "    world_depth_1_points = transform(c2w, depth_1_points)\n",
    "    world_depth_1_points_direction = world_depth_1_points - origin\n",
    "    norms = np.linalg.norm(world_depth_1_points_direction, axis=1, keepdims=True)\n",
    "    directions = world_depth_1_points_direction/ norms\n",
    "\n",
    "    return origin, directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef93706-259c-4fa8-ab76-aa2e37763eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaysData(Dataset):\n",
    "    def __init__(self, img_train, K, c2ws_train):\n",
    "        self.img = img_train\n",
    "        self.c2ws = c2ws_train\n",
    "        self.K = K\n",
    "        self.height = 200\n",
    "        self.width = 200\n",
    "        self.length = len(self.img) * self.height * self.width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img) * self.height * self.width\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_index = idx // (self.width*self.height)\n",
    "        residual = idx % (self.width*self.height)\n",
    "        temp_height = residual // self.height \n",
    "        temp_width = residual % self.width \n",
    "        c2w = self.c2ws[img_index]\n",
    "        uv = np.array([[temp_height+0.5, temp_width+0.5]])\n",
    "        ray_o, ray_d = pixel_to_ray(self.K, c2w, uv)\n",
    "        pixel = self.img[img_index,temp_height,temp_width,:]\n",
    "        sample = {'rays_o':ray_o[0],\n",
    "                  \"rays_d\":ray_d[0],\n",
    "                 \"pixels\":pixel}\n",
    "        return sample\n",
    "\n",
    "    def sample_rays(self, num_samples):\n",
    "        rays_o = []\n",
    "        rays_d = []\n",
    "        pixels = []\n",
    "        # random_numbers = [random.randint(0,self.length -1) for _ in range(num_samples)]\n",
    "        random_numbers = np.random.randint(0, self.length - 1, size=num_samples) \n",
    "        for random_number in random_numbers:\n",
    "            img_index = random_number // (self.width*self.height)\n",
    "            residual = random_number % (self.width*self.height)\n",
    "            temp_height = residual // self.height \n",
    "            temp_width = residual % self.width \n",
    "            c2w = self.c2ws[img_index]\n",
    "            uv = np.array([[temp_height+0.5, temp_width+0.5]])\n",
    "            ray_o, ray_d = pixel_to_ray(self.K, c2w, uv)\n",
    "            rays_o.append(ray_o[0])\n",
    "            rays_d.append(ray_d[0])\n",
    "            pixels.append(self.img[img_index,temp_height,temp_width,:])\n",
    "        return rays_o, rays_d,pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88a8f95-6489-402d-82cc-527bdc0ae232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_along_rays(rays_o, rays_d, n_samples=32, perturb=True):\n",
    "    far = 6 \n",
    "    near = 2\n",
    "    \n",
    "    t_values = torch.linspace(near, far, n_samples).to(device)\n",
    "    ran_values = (torch.rand((len(rays_o), n_samples)) * (far - near) / n_samples).to(device)\n",
    "\n",
    "    # Create 3D grid for rays_o and rays_d\n",
    "    ray_o_grid = rays_o[:, None, :].repeat(1, n_samples, 1)\n",
    "    ray_d_grid = rays_d[:, None, :].repeat(1, n_samples, 1)\n",
    "\n",
    "    # Compute points without explicit loops\n",
    "    p_t = t_values + ran_values\n",
    "    p_t = p_t.to(device)\n",
    "    points = ray_o_grid + ray_d_grid * p_t.unsqueeze(2)\n",
    "\n",
    "    return points.view(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "851f8d1c-69c8-4e94-8bbd-db1a9b933c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volrend(sigmas, rgbs, step_size):\n",
    "    sigmas = sigmas.to(device)\n",
    "    rgbs = rgbs.to(device)\n",
    "    size_to_prepend = (sigmas.size(0), 1, 1)\n",
    "\n",
    "    zeros_to_prepend = torch.zeros(size_to_prepend, dtype=sigmas.dtype).to(device)\n",
    "    \n",
    "    tensor_with_zeros = torch.cat((zeros_to_prepend, sigmas), dim=1).to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "    cum_sigmas = torch.cumsum(tensor_with_zeros,dim=1)[:,:-1].to(device)\n",
    "    T = torch.exp(-cum_sigmas*step_size).to(device)\n",
    "    interval_sigmas = 1 - torch.exp(-sigmas*step_size).to(device)\n",
    "    weights = T * interval_sigmas\n",
    "    colors = rgbs * weights\n",
    "    cum_colors = torch.sum(colors, dim=1).to(device)\n",
    "\n",
    "    return cum_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdd6bac4-8401-4309-9b95-ea2446b73df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Residual_block, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.linear_1 = nn.Linear(dim, dim)\n",
    "        self.layer_norm_1 = nn.LayerNorm(normalized_shape=dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_2 = nn.Linear(dim, dim)\n",
    "        self.layer_norm_2 = nn.LayerNorm(normalized_shape=dim)\n",
    "        nn.init.kaiming_normal_(self.linear_1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.linear_2.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self,x):\n",
    "        origin_x = x\n",
    "        x = self.linear_1(x)\n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.layer_norm_2(x)\n",
    "        x = self.relu(x + origin_x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41978bf8-8dfc-4e8d-a309-cd04f21034be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nerf_model(nn.Module):\n",
    "    def __init__(self,high_fre_level, high_fre_level_angle, hidden_dim):\n",
    "        super(Nerf_model, self).__init__()\n",
    "        self.high_fre_level = high_fre_level\n",
    "        self.high_fre_level_angle = high_fre_level_angle\n",
    "        self.pe_dim = 3+high_fre_level*6\n",
    "        self.pe_dim_angle = 3 + 6 * high_fre_level_angle\n",
    "        self.input_layer = nn.Linear(3+high_fre_level*6, hidden_dim)\n",
    "        self.residual_block_1 = Residual_block(hidden_dim)\n",
    "        self.residual_block_2 = Residual_block(hidden_dim)\n",
    "        self.residual_block_3 = Residual_block(hidden_dim)\n",
    "        \n",
    "        self.hidden_layer_1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hidden_layer_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.hidden_layer_concat_angle = nn.Linear(hidden_dim + self.pe_dim_angle, hidden_dim//2)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.hidden_layer_concat_angle.weight, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim//2, 3)\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.density_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        power_terms_pos = (torch.exp2(torch.arange(0, high_fre_level))*3.14159).to(device)\n",
    "        \n",
    "        power_terms_angle = (torch.exp2(torch.arange(0, high_fre_level_angle))*3.14159).to(device)\n",
    "        \n",
    "        self.power_matrix_pos= torch.zeros(3, self.high_fre_level *3).to(device)\n",
    "        for i in range(3):\n",
    "            self.power_matrix_pos[i,i*high_fre_level:(i+1)*high_fre_level] = power_terms_pos\n",
    "\n",
    "        self.power_matrix_angle = torch.zeros(3, self.high_fre_level_angle  *3).to(device)\n",
    "        for i in range(3):\n",
    "            self.power_matrix_angle[i,i*high_fre_level_angle :(i+1)*high_fre_level_angle ] = power_terms_angle\n",
    "\n",
    "\n",
    "        self.middle_layer_norm = nn.LayerNorm(normalized_shape=hidden_dim) \n",
    "        \n",
    "        self.last_layer_norm = nn.LayerNorm(normalized_shape=hidden_dim//2) \n",
    "\n",
    "    def positional_encoding(self, data, high_fre_level, power_matrix):\n",
    "\n",
    "        powered_data = data @ power_matrix\n",
    "        sin_matrix = torch.sin(powered_data).to(device)\n",
    "        cos_matrix = torch.cos(powered_data).to(device)\n",
    "\n",
    "        pe = torch.cat((data, sin_matrix, cos_matrix),1).to(device)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def forward(self,pos, angle):\n",
    "                \n",
    "        pos_pe = self.positional_encoding(pos, self.high_fre_level, self.power_matrix_pos)\n",
    "        \n",
    "        origin_x = pos_pe\n",
    "        x = self.input_layer(origin_x)\n",
    "        x = self.residual_block_1(x)\n",
    "        x = self.residual_block_2(x)\n",
    "        x = self.residual_block_3(x)\n",
    "        x = self.hidden_layer_1(x)\n",
    "        sigmas = self.density_layer(x)\n",
    "        sigmas = self.relu(sigmas)\n",
    "\n",
    "        # x = self.middle_layer_norm(x)\n",
    "        x = self.hidden_layer_2(x)\n",
    "\n",
    "        angle_pe = self.positional_encoding(angle, self.high_fre_level_angle, self.power_matrix_angle)\n",
    "        # angle_input = torch.cat((angle,angle_pe),dim=1)\n",
    "        concated_x = torch.cat((x,angle_pe), dim = 1).float()\n",
    "        x = self.hidden_layer_concat_angle(concated_x)\n",
    "        x = self.last_layer_norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9493e60b-c480-4911-bc9d-a321fcec5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "715205de-392f-4c3a-895d-1e903ed4922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Nerf_model(nn.Module):\n",
    "#     def __init__(self,high_fre_level, high_fre_level_angle, hidden_dim):\n",
    "#         super(Nerf_model, self).__init__()\n",
    "#         self.high_fre_level = high_fre_level\n",
    "#         self.high_fre_level_angle = high_fre_level_angle\n",
    "#         self.pe_dim = 3+high_fre_level*6\n",
    "#         self.pe_dim_angle = 3 + 6 * high_fre_level_angle\n",
    "#         self.input_layer = nn.Linear(3+high_fre_level*6, hidden_dim)\n",
    "#         # self.input_layer = nn.Linear(2, hidden_dim)\n",
    "#         hidden_layer_list = []\n",
    "\n",
    "\n",
    "        \n",
    "#         for i in range(3):\n",
    "#             hidden_layer_list.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "#             hidden_layer_list.append(nn.ReLU())\n",
    "#         self.hidden_layer_1 = nn.Sequential(*hidden_layer_list)\n",
    "\n",
    "#         self.concat_hidden_layer = nn.Linear(hidden_dim + self.pe_dim,hidden_dim)\n",
    "        \n",
    "#         hidden_layer_list = []\n",
    "#         for i in range(2):\n",
    "#             hidden_layer_list.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "#             hidden_layer_list.append(nn.ReLU())\n",
    "#         self.hidden_layer_2 = nn.Sequential(*hidden_layer_list)\n",
    "\n",
    "#         self.hidden_layer_3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.hidden_layer_4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.hidden_layer_5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.hidden_layer_concat_angle = nn.Linear(hidden_dim + self.pe_dim_angle, hidden_dim//2)\n",
    "\n",
    "#         self.out = nn.Linear(hidden_dim//2, 3)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.density_layer = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "#         power_terms_pos = (torch.exp2(torch.arange(0, high_fre_level))*3.14159).to(device)\n",
    "        \n",
    "#         power_terms_angle = (torch.exp2(torch.arange(0, high_fre_level_angle))*3.14159).to(device)\n",
    "        \n",
    "#         self.power_matrix_pos= torch.zeros(3, self.high_fre_level *3).to(device)\n",
    "#         for i in range(3):\n",
    "#             self.power_matrix_pos[i,i*high_fre_level:(i+1)*high_fre_level] = power_terms_pos\n",
    "\n",
    "#         self.power_matrix_angle = torch.zeros(3, self.high_fre_level_angle  *3).to(device)\n",
    "#         for i in range(3):\n",
    "#             self.power_matrix_angle[i,i*high_fre_level_angle :(i+1)*high_fre_level_angle ] = power_terms_angle\n",
    "\n",
    "#         # self.layer_norm1 = nn.LayerNorm(normalized_shape=HIDDEN_UNITS)  \n",
    "#         # self._initialize_weights()\n",
    "#         self.last_layer_norm = nn.LayerNorm(normalized_shape=hidden_dim//2) \n",
    "        \n",
    "\n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "#                 if m.bias is not None:\n",
    "#                     nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     def positional_encoding(self, data, high_fre_level, power_matrix):\n",
    "\n",
    "#         powered_data = data @ power_matrix\n",
    "#         sin_matrix = torch.sin(powered_data).to(device)\n",
    "#         cos_matrix = torch.cos(powered_data).to(device)\n",
    "\n",
    "#         pe = torch.cat((data, sin_matrix, cos_matrix),1).to(device)\n",
    "\n",
    "#         return pe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     def forward_phase_1(self, origin_x):\n",
    "\n",
    "#         x = self.input_layer(origin_x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.hidden_layer_1(x)\n",
    "#         x = torch.cat((x,origin_x), dim = 1)\n",
    "#         x = self.concat_hidden_layer(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.hidden_layer_2(x)\n",
    "#         x = self.hidden_layer_3(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "        \n",
    "#     def forward(self, pos, angle):\n",
    "        \n",
    "#         pos_pe = self.positional_encoding(pos, self.high_fre_level, self.power_matrix_pos)\n",
    "        \n",
    "#         origin_x = pos_pe\n",
    "#         x = self.forward_phase_1(origin_x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#         sigmas = self.density_layer(x)\n",
    "#         sigmas = self.relu(sigmas)\n",
    "        \n",
    "#         x = self.hidden_layer_4(x)\n",
    "#         angle_pe = self.positional_encoding(angle, self.high_fre_level_angle, self.power_matrix_angle)\n",
    "#         # angle_input = torch.cat((angle,angle_pe),dim=1)\n",
    "#         concated_x = torch.cat((x,angle_pe), dim = 1).float()\n",
    "#         x = self.hidden_layer_concat_angle(concated_x)\n",
    "#         x = self.last_layer_norm(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.out(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x, sigmas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed7affde-65aa-4c74-9c96-46665bf4b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Nerf_model(30,10,256).to(device)\n",
    "step_size = (6-2)/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0882aa75-d0d3-4478-80bc-0db0f534542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2da15bb5-e9c8-47b0-a426-b36273b42108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                           | 1/400 [00:00<04:51,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [0], Loss: 0.035258326679468155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████▎                                    | 50/400 [00:23<03:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [49], Loss: 0.03232917934656143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▍                               | 99/400 [00:48<02:43,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [98], Loss: 0.03199579939246178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████▏                         | 148/400 [01:13<02:16,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [147], Loss: 0.02739843539893627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▏                    | 197/400 [01:38<01:48,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [196], Loss: 0.025908321142196655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▏               | 246/400 [02:01<01:20,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [245], Loss: 0.0235576331615448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████▏          | 295/400 [02:25<00:56,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [294], Loss: 0.022329488769173622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▎     | 344/400 [02:48<00:29,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [343], Loss: 0.02249150536954403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████▎| 393/400 [03:12<00:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [392], Loss: 0.019733626395463943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [03:15<00:00,  2.04it/s]\n",
      "  0%|                                           | 1/400 [00:00<05:55,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [0], Loss: 0.01948956958949566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████▎                                    | 50/400 [00:24<03:05,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [49], Loss: 0.01855948381125927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▍                               | 99/400 [00:48<02:44,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [98], Loss: 0.018138885498046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████▏                         | 148/400 [01:13<02:21,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [147], Loss: 0.017201313748955727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▏                    | 197/400 [01:36<01:47,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [196], Loss: 0.01672467216849327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▏               | 246/400 [02:00<01:26,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [245], Loss: 0.016931967809796333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████▏          | 295/400 [02:24<00:55,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [294], Loss: 0.01626514084637165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▎     | 344/400 [02:48<00:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [343], Loss: 0.015142186544835567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████▎| 393/400 [03:12<00:03,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [392], Loss: 0.01447840966284275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [03:15<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "# criterion = PSNRWithMSELoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "number_epoch  = 2\n",
    "model.train()\n",
    "# scheduler = StepLR(optimizer, step_size=70, gamma=0.1)\n",
    "# for i in range(number_iteration):\n",
    "\n",
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "dataloader = DataLoader(dataset, batch_size=10000,\n",
    "                        shuffle=True)\n",
    "\n",
    "for e in range(number_epoch):\n",
    "    for i_batch, sample_batched in enumerate(tqdm(dataloader)):\n",
    "        # print(len(sample_batched['pixels']))\n",
    "        # rays_o, rays_d, pixels = dataset.sample_rays(10000)\n",
    "        # rays_o, rays_d, pixels = dataset.sample_rays_one(1000)\n",
    "        # t1 = time.time()\n",
    "        rays_o = sample_batched['rays_o'].squeeze()\n",
    "        rays_d = sample_batched['rays_d'].squeeze()\n",
    "        pixels = sample_batched['pixels']\n",
    "        rays_o = rays_o.float().to(device)\n",
    "        rays_d = rays_d.float().to(device)\n",
    "        # rays_d = np.array(rays_d)\n",
    "        # rays_o = np.array(rays_o)\n",
    "        # rays_d = torch.tensor(rays_d).to(device)\n",
    "        # rays_o = torch.tensor(rays_o).to(device)\n",
    "        points = sample_along_rays(rays_o, rays_d)\n",
    "        \n",
    "    \n",
    "        points = points.float().to(device)\n",
    "        # points = np.array(points)\n",
    "        # rays_d = np.array(rays_d)\n",
    "        # points = torch.tensor(points).to(device)\n",
    "        # rays_d = torch.tensor(rays_d).to(device)\n",
    "    \n",
    "        rays_d = torch.unsqueeze(rays_d,1)\n",
    "        rays_d = rays_d.repeat(1,n_samples,1)\n",
    "        rays_d = rays_d.view(-1,3)\n",
    "        \n",
    "        # t2 = time.time()\n",
    "        # print('p',t2-t1)\n",
    "        # t1 = t2\n",
    "        \n",
    "        rgbs, sigmas = model(points, rays_d)\n",
    "        \n",
    "        # t2 = time.time()\n",
    "        # print('forward',t2-t1)\n",
    "        # t1 = t2\n",
    "        \n",
    "        rgbs = rgbs.to(device)\n",
    "        sigmas = sigmas.to(device)\n",
    "        # sigams = model.foward_dentisy()\n",
    "        sigmas = sigmas.view(-1, n_samples, 1)\n",
    "        rgbs = rgbs.view(-1, n_samples, 3)\n",
    "        \n",
    "    \n",
    "    \n",
    "        rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "\n",
    "                \n",
    "        # t2 = time.time()\n",
    "        # print('render',t2-t1)\n",
    "        # t1 = t2\n",
    "        # print(\"render\",rendered_colors[0])\n",
    "        # print(\"pixels\",pixels[0])\n",
    "    \n",
    "        pixels = pixels.float().to(device)\n",
    "        # pixels = np.array(pixels)\n",
    "        # pixels = torch.tensor(pixels).float().to(device)\n",
    "    \n",
    "        # print(rendered_colors)\n",
    "        loss = criterion(rendered_colors, pixels)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "                        \n",
    "        # t2 = time.time()\n",
    "        # print('backward',t2-t1)\n",
    "        # t1 = t2\n",
    "        # scheduler.step()\n",
    "        if i_batch % 49 == 0:\n",
    "            print(f'iteration [{i_batch}], Loss: {loss.item()}')\n",
    "    # scheduler.step()\n",
    "    # torch.save(model.state_dict(), 'weights_%s.pth'%e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5c2c08e-c25d-43b2-b34b-592450743edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights_arc2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69614139-eaf8-45f6-a9e3-cea19b47781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'weights_arc2.pth'  # Provide the correct path to the saved weights file\n",
    "model.load_state_dict(torch.load(weights_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
