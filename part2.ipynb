{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c446ff2-9c90-4db2-9dab-3ccb9848386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.io as skio\n",
    "import torch.optim as optim\n",
    "import skimage as sk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a984cd0-189d-4285-b3f6-bb6ceb86a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f\"lego_200x200.npz\")\n",
    "images_train = data[\"images_train\"] / 255.0\n",
    "c2ws_train = data[\"c2ws_train\"]\n",
    "images_val = data[\"images_val\"] / 255.0\n",
    "c2ws_val = data[\"c2ws_val\"]\n",
    "c2ws_test = data[\"c2ws_test\"]\n",
    "focal = data[\"focal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1af29b4b-5ed2-4079-ae85-e48cd58ba5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 200, 200, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d09713a-f81e-4b4a-bbf9-2ebbb6224f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 200\n",
    "width = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c066449d-5ee8-4f80-9288-69dd904a52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[focal,0,width/2],[0,focal,height/2],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6756e1cb-d746-4ac7-b8af-8df9afd1e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w = c2ws_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3f13f49-7864-439c-b988-78a168fbe204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.99902189e-01, -4.19224519e-03,  1.33457193e-02,\n",
       "        -5.37983216e-02],\n",
       "       [-1.39886811e-02,  2.99659073e-01, -9.53943670e-01,\n",
       "         3.84547043e+00],\n",
       "       [-4.65661287e-10, -9.54037189e-01, -2.99688309e-01,\n",
       "         1.20808232e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704781ce-f547-4535-bcd4-2107d6c7d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(c2w, x_c):\n",
    "    #camera to world\n",
    "    num_rows = len(x_c)\n",
    "    ones_column = np.ones((num_rows, 1))\n",
    "    x_c_with_one = np.concatenate((x_c, ones_column), axis=1)\n",
    "    x = (c2w @ x_c_with_one.T).T\n",
    "    return x[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68e3503d-9a43-4f25-b9f3-31ae9a749683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05379832  3.84547043  1.20808232]]\n"
     ]
    }
   ],
   "source": [
    "aaa = np.array([[0,0,0]])\n",
    "print(transform(c2w, aaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a078e626-ee0c-469c-83c8-6bf47de26101",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = np.linalg.inv(c2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "722fc99a-6504-4827-b98c-4e610b8a4416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.99902118e-01 -1.39886803e-02 -1.19264272e-10]\n",
      " [-4.19224401e-03  2.99659014e-01 -9.54037109e-01]\n",
      " [ 1.33457230e-02 -9.53943931e-01 -2.99688425e-01]]\n",
      "[ 6.33068112e-10 -5.15363604e-08  4.03112944e+00]\n"
     ]
    }
   ],
   "source": [
    "print(w2c[:3,:3])\n",
    "print(w2c[:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6392c32-88ff-463e-80dd-374f766d9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05379832  3.84547043  1.20808232]\n"
     ]
    }
   ],
   "source": [
    "print(-np.linalg.inv(w2c[:3,:3]) @ w2c[:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c967571e-60d8-4f6c-907e-f14cae891ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_camera(K, uv,s):\n",
    "    num_rows = len(uv)\n",
    "    ones_column = np.ones((num_rows, 1))\n",
    "    uv_with_one = np.concatenate((uv, ones_column), axis=1)\n",
    "    result = (np.linalg.inv(K) @ uv_with_one.T).T\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0258127d-c836-48cd-b60f-ca73d01d81f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1       ]\n",
      " [15.64640534]\n",
      " [32.96680148]\n",
      " [34.69884724]]\n",
      "[[1.         0.         0.        ]\n",
      " [0.58160324 0.57521199 0.57521199]\n",
      " [0.57937073 0.57633738 0.57633738]\n",
      " [0.57926996 0.57638802 0.57638802]]\n"
     ]
    }
   ],
   "source": [
    "aaa = np.array([[1,2,3],[10,11,12],[20,21,22],[21,22,23]])\n",
    "b = np.array([[0.9,2,3]])\n",
    "c = aaa - b\n",
    "norms = np.linalg.norm(c, axis=1, keepdims=True)\n",
    "print(norms)\n",
    "print(c/norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c50e2f-acf4-4e04-a9a2-b9e4d60170b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2132818-51f7-48d2-a045-74ebd6661bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_ray(K, c2w, uv):\n",
    "    zeros = np.array([[0,0,0]])\n",
    "    origin = transform(c2w, zeros)\n",
    "    depth_1_points = pixel_to_camera(K, uv, 1)\n",
    "    world_depth_1_points = transform(c2w, depth_1_points)\n",
    "    world_depth_1_points_direction = world_depth_1_points - origin\n",
    "    norms = np.linalg.norm(world_depth_1_points_direction, axis=1, keepdims=True)\n",
    "    directions = world_depth_1_points_direction/ norms\n",
    "\n",
    "    return origin, directions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee2f75-fe71-4d5f-9e37-80f5e4524e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd398744-4b0a-4273-b008-1c911fd4b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaysData(Dataset):\n",
    "    def __init__(self, img_train, K, c2ws_train):\n",
    "        self.img = img_train\n",
    "        self.c2ws = c2ws_train\n",
    "        self.K = K\n",
    "        self.height = 200\n",
    "        self.width = 200\n",
    "        self.length = len(self.img) * self.height * self.width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img * self.height * self.width)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "        # x = idx // self.width \n",
    "        # y = idx % self.width \n",
    "        # rgb = [self.image[x,y,0],\n",
    "        #        self.image[x,y,1],\n",
    "        #        self.image[x,y,2]]\n",
    "        # sample = {'input':torch.tensor([x/self.height,y/ self.width]),\n",
    "        #           \"label\":torch.tensor(rgb)}\n",
    "        # return sample\n",
    "\n",
    "    def sample_rays(self, num_samples):\n",
    "        rays_o = []\n",
    "        rays_d = []\n",
    "        pixels = []\n",
    "        random_numbers = [random.randint(0,self.length -1) for _ in range(num_samples)]\n",
    "        for random_number in random_numbers:\n",
    "            img_index = random_number // (self.width*self.height)\n",
    "            residual = random_number % (self.width*self.height)\n",
    "            temp_height = residual // self.height\n",
    "            temp_width = residual % self.width\n",
    "            c2w = self.c2ws[img_index]\n",
    "            uv = np.array([[temp_height, temp_width]])\n",
    "            ray_o, ray_d = pixel_to_ray(self.K, c2w, uv)\n",
    "            rays_o.append(ray_o[0])\n",
    "            rays_d.append(ray_d[0])\n",
    "            pixels.append(self.img[img_index,temp_height,temp_width,:])\n",
    "        return rays_o, rays_d,pixels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76051041-06ab-424a-855f-8f5016a5096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "rays_o, rays_d, pixels = dataset.sample_rays(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da66976-9b61-48e9-8126-2acdcd424fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_along_rays(rays_o, rays_d, perturb = True):\n",
    "    far = 6 \n",
    "    near = 2\n",
    "    n_samples = 32\n",
    "    points = []\n",
    "    for ray_o, ray_d in zip(rays_o, rays_d):\n",
    "        for t in np.linspace(near, far, n_samples):\n",
    "            ran = random.uniform(0, (far - near)/n_samples)\n",
    "            p_t = t + ran\n",
    "            points.append(ray_o + ray_d * p_t)\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b92b103b-0fa5-4c78-b3c7-3f0ae98726d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "points = sample_along_rays(rays_o, rays_d)\n",
    "print(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af6b290-7144-4d3c-9b96-a111cde81f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import viser, time  # pip install viser\n",
    "import numpy as np\n",
    "\n",
    "# --- You Need to Implement These ------\n",
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "rays_o, rays_d, pixels = dataset.sample_rays(5)\n",
    "points = sample_along_rays(rays_o, rays_d, perturb=True)\n",
    "H, W = images_train.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d706fc-dd2c-4e67-b0a8-18e03951cd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL requested! <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL requested! \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────── <span style=\"font-weight: bold\">viser</span> ──────────────────────────────╮\n",
       "│             ╷                                                    │\n",
       "│   HTTP      │ http://0.0.0.0:8080                                │\n",
       "│   Websocket │ ws://0.0.0.0:8080                                  │\n",
       "│   Share URL │ https://transparent-augmented.share.viser.studio   │\n",
       "│             ╵                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭───────────────────────────── \u001b[1mviser\u001b[0m ──────────────────────────────╮\n",
       "│             ╷                                                    │\n",
       "│   HTTP      │ http://0.0.0.0:8080                                │\n",
       "│   Websocket │ ws://0.0.0.0:8080                                  │\n",
       "│   Share URL │ https://transparent-augmented.share.viser.studio   │\n",
       "│             ╵                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">411</span> persistent messages\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m411\u001b[0m persistent messages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m     server\u001b[38;5;241m.\u001b[39madd_spline_catmull_rom(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/rays/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, positions\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mstack((o, o \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6.0\u001b[39m)),\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m server\u001b[38;5;241m.\u001b[39madd_point_cloud(\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/samples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     colors\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(points)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     19\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     20\u001b[0m     point_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "server = viser.ViserServer(share=True)\n",
    "for i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n",
    "    server.add_camera_frustum(\n",
    "        f\"/cameras/{i}\",\n",
    "        fov=2 * np.arctan2(H / 2, K[0, 0]),\n",
    "        aspect=W / H,\n",
    "        scale=0.15,\n",
    "        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n",
    "        position=c2w[:3, 3],\n",
    "        image=image\n",
    "    )\n",
    "for i, (o, d) in enumerate(zip(rays_o, rays_d)):\n",
    "    server.add_spline_catmull_rom(\n",
    "        f\"/rays/{i}\", positions=np.stack((o, o + d * 6.0)),\n",
    "    )\n",
    "server.add_point_cloud(\n",
    "    f\"/samples\",\n",
    "    colors=np.zeros_like(points).reshape(-1, 3),\n",
    "    points=points.reshape(-1, 3),\n",
    "    point_size=0.02,\n",
    ")\n",
    "time.sleep(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59ccd6c7-4214-4a59-9ce6-4419332622e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volrend(sigmas, rgbs, step_size):\n",
    "    size_to_prepend = (sigmas.size(0), 1, 1)\n",
    "\n",
    "    zeros_to_prepend = torch.zeros(size_to_prepend, dtype=sigmas.dtype)\n",
    "    \n",
    "    tensor_with_zeros = torch.cat((zeros_to_prepend, sigmas), dim=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    cum_sigmas = torch.cumsum(tensor_with_zeros,dim=1)[:,:-1]\n",
    "    T = torch.exp(-cum_sigmas*step_size)\n",
    "    interval_sigmas = 1 - torch.exp(-sigmas*step_size)\n",
    "    weights = T * interval_sigmas\n",
    "    colors = rgbs * weights\n",
    "    cum_colors = torch.sum(colors, dim=1)\n",
    "\n",
    "    return cum_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f29ba80-c2a2-408e-8e54-0730a2aa14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "sigmas = torch.rand((10, 64, 1)) * 1000\n",
    "rgbs = torch.rand((10, 64, 3))\n",
    "step_size = (6.0 - 2.0) / 64\n",
    "rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "correct = torch.tensor([\n",
    "  [0.6020, 0.0316, 0.9366],\n",
    "  [0.0620, 0.2249, 0.1381],\n",
    "  [0.7785, 0.4253, 0.7124],\n",
    "  [0.8748, 0.5055, 0.7411],\n",
    "  [0.2240, 0.5240, 0.4298],\n",
    "  [0.0531, 0.7500, 0.0501],\n",
    "  [0.0458, 0.9415, 0.4620],\n",
    "  [0.6692, 0.3450, 0.0991],\n",
    "  [0.7392, 0.6365, 0.3080],\n",
    "  [0.2425, 0.9346, 0.9305]]\n",
    ")\n",
    "assert torch.allclose(rendered_colors, correct, rtol=1e-4, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4aa32-9c1c-4300-af6b-acba881a3cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
